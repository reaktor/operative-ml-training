{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports and parameter setting\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql import functions as Funcs\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import ensemble\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "inputPath = '/home/jovyan/work/data/autot4.7.csv'\n",
    "\n",
    "# Create a spark session\n",
    "session = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Car data\") \\\n",
    "    .config('spark.driver.memory', '5G') \\\n",
    "    .config('spark.executor.memory', '5G') \\\n",
    "    .getOrCreate()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read input data into a spark data frame\n",
    "# remove . from column names\n",
    "inDf = session.read \\\n",
    "    .format(\"org.apache.spark.csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \";\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(inputPath)\n",
    "    \n",
    "newColnames = [col.replace('.','_',5) for col in inDf.columns]\n",
    "inDf = inDf.toDF(*newColnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Select a subset of columns and set their types \n",
    "carsDf = inDf.select(\n",
    "    'ajoneuvoluokka',\n",
    "    'ajoneuvonkaytto',\n",
    "    'ajoneuvoryhma',\n",
    "    'korityyppi',\n",
    "    'ohjaamotyyppi',\n",
    "    'kayttovoima',\n",
    "    'istumapaikkojenLkm',\n",
    "    'sylintereidenLkm',\n",
    "    'vaihteisto',\n",
    "    'alue',\n",
    "    'kunta',\n",
    "    'merkki',\n",
    "    'malli',\n",
    "    'merkki_l_malli',\n",
    "    'kayttoonotto_pvm_imputoitu',\n",
    "    inDf['omamassa'].cast(\"int\"),\n",
    "    inDf['iskutilavuus'].cast(\"int\"),\n",
    "    inDf['suurinNettoteho'].cast(\"int\"),\n",
    "    inDf['matkamittarilukema'].cast(\"int\"),\n",
    "    inDf['kayttoonottoVuosi'].cast(\"int\"),\n",
    "    inDf['ensirekVuosi'].cast(\"int\"),\n",
    "    inDf['ensirekisterointipvm'].cast(\"timestamp\"),\n",
    "    inDf['kayttoonottopvm'].cast(\"timestamp\"),\n",
    "    inDf['max_date'].cast(\"timestamp\"),\n",
    "    inDf['kayttoonotto'].cast(\"timestamp\")\n",
    ")\n",
    "# List of variables by types strings are called 'factors'\n",
    "factorVars = [\n",
    "    'ajoneuvoluokka',\n",
    "    'ajoneuvonkaytto',\n",
    "    'ajoneuvoryhma',\n",
    "    'korityyppi',\n",
    "    'ohjaamotyyppi',\n",
    "    'kayttovoima',\n",
    "    'istumapaikkojenLkm',\n",
    "    'sylintereidenLkm',\n",
    "    'vaihteisto',\n",
    "    'alue',\n",
    "    'kunta',\n",
    "    'merkki',\n",
    "    'malli',\n",
    "    'merkki_l_malli',\n",
    "    'kayttoonotto_pvm_imputoitu'\n",
    "]\n",
    "numericVars = [\n",
    "    'omamassa',\n",
    "    'iskutilavuus',\n",
    "    'suurinNettoteho',\n",
    "    'matkamittarilukema',\n",
    "    'kayttoonottoVuosi',\n",
    "    'ensirekVuosi'\n",
    "]\n",
    "dateVars = [\n",
    "    'ensirekisterointipvm',\n",
    "    'kayttoonottopvm',\n",
    "    'max_date',\n",
    "    'kayttoonotto'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate new columns from original\n",
    "carsDf = carsDf.withColumn(\n",
    "    'usageDays', \n",
    "    (carsDf['max_date'].cast('long')-carsDf['kayttoonottopvm'].cast('long'))/(24.0 * 3600.0)\n",
    ")\n",
    "numericVars.append('usageDays')\n",
    "\n",
    "carsDf = carsDf.withColumn(\n",
    "    'mileagePerDay', \n",
    "    carsDf['matkamittarilukema'].cast('float')/carsDf['usageDays']\n",
    ")\n",
    "numericVars.append('mileagePerDay')\n",
    "\n",
    "# Truncate values to sensible values\n",
    "carsDf = carsDf.withColumn(\n",
    "    'mileagePerDay', \n",
    "    Funcs.when(carsDf['mileagePerDay']>200, 200).otherwise(carsDf['mileagePerDay'])\n",
    ")\n",
    "# Or filter out unsensible values (car mass)\n",
    "carsDf = carsDf.filter(carsDf.omamassa.between(1, 4000))\n",
    "\n",
    "carsDf = carsDf.filter(carsDf.matkamittarilukema.between(1e4, 1e6))\n",
    "\n",
    "#Only cars that are still in use and data has been collected\n",
    "carsDf = carsDf.filter(carsDf.kayttoonottoVuosi.between(1990, 2011))\n",
    "\n",
    "# Imputation gives strange results\n",
    "carsDf = carsDf.filter(carsDf.kayttoonotto_pvm_imputoitu == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split data into training (20%), test (10%) and rest (70%) sets\n",
    "# numbers are chosen here for convenience, 20% of this set is enought to fit model\n",
    "splits = carsDf.randomSplit([0.1, 0.1, 0.8], 220274)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get modelling data to pandas data frame\n",
    "modelDf = splits[0].toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get test data into pandas DF\n",
    "# testDf = splits[1].toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some more filtering\n",
    "modelDf = modelDf[\n",
    "    (modelDf.ajoneuvonkaytto == 'Yksityinen') &\n",
    "    (modelDf.ajoneuvoryhma.isin(['NA', 'Matkailuauto', 'Maastohenkil√∂auto']))\n",
    "]         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# numeric and factor type variables are treated differently\n",
    "\n",
    "# first pick numerical variables into training data\n",
    "trainDf = modelDf[numericVars]\n",
    "\n",
    "# remove target variable into separate vector\n",
    "trainDf.pop('mileagePerDay')\n",
    "target = trainDf.pop('matkamittarilukema')\n",
    "target = np.log(target)\n",
    "\n",
    "\n",
    "# numerical data has missing values, replace missing with average of that variable\n",
    "# Good idea: make additional variable for denoting that the value was missing\n",
    "imputer = Imputer()\n",
    "XImputed = imputer.fit_transform(trainDf)\n",
    "\n",
    "# scale numerical variables to zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "XScaled = scaler.fit_transform(XImputed)\n",
    "\n",
    "# put model fitting data into pandas data frame\n",
    "X = pd.DataFrame(XScaled, columns=trainDf.columns, index=trainDf.index)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# factor variables are included through dummy variable encoding\n",
    "vars = ['ajoneuvoryhma', 'kayttovoima', 'vaihteisto', 'istumapaikkojenLkm', 'ohjaamotyyppi', 'korityyppi']\n",
    "for c in vars:\n",
    "    tmp = pd.get_dummies(modelDf[c], prefix=c)\n",
    "    # add dummy variables to fitting data\n",
    "    X[tmp.columns] = tmp\n",
    "\n",
    "print(X.shape)\n",
    "X.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model\n",
    "Fit a linear model to the data. Fitting done with elastic-net algorithm\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for now, just using the default parameters (usually not enough)\n",
    "enet = ElasticNet()\n",
    "enet.fit(X, target)\n",
    "\n",
    "# print results\n",
    "pd.Series(enet.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the prediction vs. true values\n",
    "plotDf = pd.DataFrame({'prediction': enet.predict(X), 'true_value': target})\n",
    "plotDf['residual'] = plotDf.true_value-plotDf.prediction\n",
    "zz = np.array([0, plotDf.prediction.max()])\n",
    "#fig, axes = plt.subplots()\n",
    "plotDf.plot.scatter(x='prediction', y='true_value')\n",
    "plt.plot(zz, zz, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(plotDf.residual, bins=100, kde=False)\n",
    "plt.xlim(-4e5,4e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l1s = (1-np.logspace(0,-2,num=5))\n",
    "enetCV = ElasticNetCV(l1_ratio=l1s, alphas=np.logspace(-8,-3,num=5), max_iter=5000)\n",
    "enetCV.fit(X, target)\n",
    "\n",
    "# print results\n",
    "print(enetCV.alphas_)\n",
    "print(enetCV.alpha_)\n",
    "print(l1s)\n",
    "print(enetCV.l1_ratio_)\n",
    "pd.Series(enetCV.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = pd.DataFrame(enetCV.mse_path_.mean(axis=2), index=l1s, columns=enetCV.alphas_)\n",
    "sns.heatmap(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the prediction vs. true values\n",
    "plotDf = pd.DataFrame({'prediction': enetCV.predict(X), 'true_value': target})\n",
    "plotDf['residual'] = plotDf.true_value-plotDf.prediction\n",
    "zz = np.array([plotDf.prediction.min(), plotDf.prediction.max()])\n",
    "#fig, axes = plt.subplots()\n",
    "plotDf.plot.scatter(x='prediction', y='true_value', alpha=.02)\n",
    "plt.plot(zz, zz, 'r-')\n",
    "plt.show()\n",
    "sns.distplot(plotDf.residual, bins=100, kde=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbr = ensemble.GradientBoostingRegressor(\n",
    "    n_estimators=400,\n",
    "    max_depth=3,\n",
    "    min_samples_split=5,\n",
    "    learning_rate=0.02,\n",
    "    loss='lad',\n",
    "    max_features='sqrt',\n",
    "    verbose=1\n",
    ")\n",
    "gbr.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the prediction vs. true values\n",
    "plotDf = pd.DataFrame({'prediction': gbr.predict(X), 'true_value': target})\n",
    "plotDf['residual'] = plotDf.true_value-plotDf.prediction\n",
    "zz = np.array([plotDf.prediction.min(), plotDf.prediction.max()])\n",
    "#fig, axes = plt.subplots()\n",
    "plotDf.plot.scatter(x='prediction', y='true_value', alpha=.1)\n",
    "plt.plot(zz, zz, 'r-')\n",
    "plt.show()\n",
    "sns.distplot(plotDf.residual, bins=100, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importance = gbr.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featDf=pd.Series(data=feature_importance, index=X.columns)\n",
    "featDf.plot(kind='barh', figsize=(7, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the fitted model and other relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    {\n",
    "        'model': gbr, \n",
    "        'scaler': scaler, \n",
    "        'imputer': imputer, \n",
    "        'trainColumns': X.columns,\n",
    "        'factorVars': factorVars,\n",
    "        'numericVars': numericVars,\n",
    "        'dateVars': dateVars\n",
    "    }, \n",
    "    open('enet.pyobj','wb')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
